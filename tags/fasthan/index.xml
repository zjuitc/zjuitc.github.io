<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>fasthan on zjuitc&#39;s sec blog</title>
    <link>https://zjuitc.github.io/tags/fasthan/</link>
    <description>Recent content in fasthan on zjuitc&#39;s sec blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 07 Feb 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://zjuitc.github.io/tags/fasthan/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>BERT在NLP中的几个框架</title>
      <link>https://zjuitc.github.io/2021/02/07/bert-nlp/</link>
      <pubDate>Sun, 07 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zjuitc.github.io/2021/02/07/bert-nlp/</guid>
      <description>BERT在NLP中的几个框架 近期调研发现，有几个优秀的使用了BERT的NLP框架
它们是：
fasthan fastHan是基于fastNLP与pytorch实现的中文自然语言处理工具，像spacy一样调用方便。
其内核为基于BERT的联合模型，其在13个语料库中进行训练，可处理中文分词、词性标注、依存分析、命名实体识别四项任务。fastHan共有base与large两个版本，分别利用BERT的前四层与前八层。base版本在总参数量150MB的情况下各项任务均有不错表现，large版本则接近甚至超越SOTA模型。
hanlp hanlp是面向生产环境的多语种自然语言处理工具包，基于PyTorch和TensorFlow 2.x双引擎，目标是普及落地最前沿的NLP技术。HanLP具备功能完善、性能高效、架构清晰、语料时新、可自定义的特点。
借助世界上最大的多语种语料库，HanLP2.1支持包括简繁中英日俄法德在内的104种语言上的10种联合任务：分词（粗分、细分2个标准，强制、合并、校正3种词典模式）、词性标注（PKU、863、CTB、UD四套词性规范）、命名实体识别（PKU、MSRA、OntoNotes三套规范）、依存句法分析（SD、UD规范）、成分句法分析、语义依存分析（SemEval16、DM、PAS、PSD四套规范）、语义角色标注、词干提取、词法语法特征提取、抽象意义表示（AMR）。
量体裁衣，HanLP提供RESTful和native两种API，分别面向轻量级和海量级两种场景。无论何种API何种语言，HanLP接口在语义上保持一致，在代码上坚持开源。</description>
    </item>
    
  </channel>
</rss>
